{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s17/s1773005/miniconda3/envs/mlp/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import rnn\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "inputs = tf.placeholder(tf.float32, [None, 120, 25], 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, 25], 'targets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_and_accuracy(data):\n",
    "    \"\"\"Calculate average error and classification accuracy across a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: Data provider which iterates over input-target batches in dataset.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple with first element scalar value corresponding to average error\n",
    "        across all batches in dataset and second value corresponding to\n",
    "        average classification accuracy across all batches in dataset.\n",
    "    \"\"\"\n",
    "    err = 0\n",
    "    acc = 0\n",
    "    for input_batch, target_batch in data:\n",
    "        err += sess.run(error, feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        acc += sess.run(accuracy, feed_dict={inputs: input_batch, targets: target_batch})\n",
    "    err /= data.num_batches\n",
    "    acc /= data.num_batches\n",
    "    return err, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1: running error average = 18.93 running acc average = 0.17\n",
      "End of epoch 2: running error average = 8.25 running acc average = 0.24\n",
      "End of epoch 3: running error average = 4.37 running acc average = 0.27\n",
      "End of epoch 4: running error average = 3.02 running acc average = 0.29\n",
      "End of epoch 5: running error average = 2.57 running acc average = 0.30\n",
      "End of epoch 6: running error average = 2.40 running acc average = 0.31\n",
      "End of epoch 7: running error average = 2.32 running acc average = 0.31\n",
      "End of epoch 8: running error average = 2.25 running acc average = 0.33\n",
      "End of epoch 9: running error average = 2.19 running acc average = 0.35\n",
      "End of epoch 10: running error average = 2.14 running acc average = 0.36\n",
      "End of epoch 11: running error average = 2.08 running acc average = 0.38\n",
      "End of epoch 12: running error average = 2.03 running acc average = 0.40\n",
      "End of epoch 13: running error average = 1.98 running acc average = 0.41\n",
      "End of epoch 14: running error average = 1.94 running acc average = 0.43\n",
      "End of epoch 15: running error average = 1.89 running acc average = 0.44\n",
      "End of epoch 16: running error average = 1.84 running acc average = 0.46\n",
      "End of epoch 17: running error average = 1.79 running acc average = 0.48\n",
      "End of epoch 18: running error average = 1.75 running acc average = 0.49\n",
      "End of epoch 19: running error average = 1.73 running acc average = 0.50\n",
      "End of epoch 20: running error average = 1.69 running acc average = 0.51\n",
      "End of epoch 21: running error average = 1.63 running acc average = 0.53\n",
      "End of epoch 22: running error average = 1.63 running acc average = 0.53\n",
      "End of epoch 23: running error average = 1.58 running acc average = 0.55\n",
      "End of epoch 24: running error average = 1.57 running acc average = 0.56\n",
      "End of epoch 25: running error average = 1.54 running acc average = 0.56\n",
      "End of epoch 26: running error average = 1.52 running acc average = 0.57\n",
      "End of epoch 27: running error average = 1.50 running acc average = 0.58\n",
      "End of epoch 28: running error average = 1.47 running acc average = 0.59\n",
      "End of epoch 29: running error average = 1.45 running acc average = 0.60\n",
      "End of epoch 30: running error average = 1.44 running acc average = 0.60\n",
      "End of epoch 31: running error average = 1.42 running acc average = 0.61\n",
      "End of epoch 32: running error average = 1.40 running acc average = 0.62\n",
      "End of epoch 33: running error average = 1.41 running acc average = 0.61\n",
      "End of epoch 34: running error average = 1.39 running acc average = 0.61\n",
      "End of epoch 35: running error average = 1.38 running acc average = 0.62\n",
      "End of epoch 36: running error average = 1.37 running acc average = 0.63\n",
      "End of epoch 37: running error average = 1.37 running acc average = 0.62\n",
      "End of epoch 38: running error average = 1.35 running acc average = 0.63\n",
      "End of epoch 39: running error average = 1.33 running acc average = 0.63\n",
      "End of epoch 40: running error average = 1.33 running acc average = 0.64\n",
      "End of epoch 41: running error average = 1.36 running acc average = 0.63\n",
      "End of epoch 42: running error average = 1.36 running acc average = 0.62\n",
      "End of epoch 43: running error average = 1.33 running acc average = 0.63\n",
      "End of epoch 44: running error average = 1.31 running acc average = 0.64\n",
      "End of epoch 45: running error average = 1.30 running acc average = 0.64\n",
      "End of epoch 46: running error average = 1.31 running acc average = 0.64\n",
      "End of epoch 47: running error average = 1.29 running acc average = 0.65\n",
      "End of epoch 48: running error average = 1.29 running acc average = 0.65\n",
      "End of epoch 49: running error average = 1.30 running acc average = 0.65\n",
      "End of epoch 50: running error average = 1.29 running acc average = 0.65\n"
     ]
    }
   ],
   "source": [
    "n_hidden_1 = 200\n",
    "time_steps = 120\n",
    "beta = 0.01 #0.009\n",
    "\n",
    "input = tf.unstack(inputs ,time_steps,1)\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([25, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, 25]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([25]))\n",
    "}\n",
    "def LSTM_1layer_200(data):\n",
    "    lstm_layer = tf.nn.rnn_cell.GRUCell(n_hidden_1)\n",
    "    LSTM_layer,_=rnn.static_rnn(lstm_layer,data,dtype=\"float32\")\n",
    "    \n",
    "    out_layer = tf.matmul(LSTM_layer[-1], weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "out_layer = LSTM_1layer_200(input)\n",
    "\n",
    "per_datapoint_errors = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=targets)\n",
    "error = tf.reduce_mean(per_datapoint_errors)\n",
    "regularizer = tf.nn.l2_loss(weights['out'])\n",
    "error = tf.reduce_mean(error + beta * regularizer)\n",
    "\n",
    "per_datapoint_pred_is_correct = tf.equal(tf.argmax(out_layer, 1), tf.argmax(targets, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(per_datapoint_pred_is_correct, tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(error)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "import data_providers_rnn as data_providers_rnn\n",
    "train_data = data_providers_rnn.MSD25GenreDataProvider('train', batch_size=50, flatten=True, one_hot=True)\n",
    "valid_data = data_providers_rnn.MSD25GenreDataProvider('test', batch_size=50, flatten=True, one_hot=True)\n",
    "\n",
    "num_epoch = 50\n",
    "error_train = []\n",
    "error_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "for e in range(num_epoch):\n",
    "    running_error = 0.\n",
    "    running_acc = 0.\n",
    "    for input_batch, target_batch in train_data:\n",
    "        _, batch_error, batch_acc = sess.run(\n",
    "            [train_step, error, accuracy], \n",
    "            feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        running_error += batch_error\n",
    "        running_acc += batch_acc\n",
    "    running_error /= train_data.num_batches\n",
    "    running_acc /= train_data.num_batches\n",
    "    print('End of epoch {0}: running error average = {1:.2f}'.format(e + 1, running_error), \n",
    "          'running acc average = {1:.2f}'.format(e + 1, running_acc))\n",
    "    error_train = np.append(error_train, running_error)\n",
    "    acc_train = np.append(acc_train, running_acc)\n",
    "    a = get_error_and_accuracy(valid_data)\n",
    "    error_test = np.append(error_test, a[0])\n",
    "    acc_test = np.append(acc_test, a[1])\n",
    "    \n",
    "Test_25 = [error_train, acc_train, error_test, acc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Test_25', Test_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
